{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from globals import ROOT_DIR\n",
    "from data_providers import TextDataProvider\n",
    "import argparse\n",
    "import configparser\n",
    "from torch import optim\n",
    "from experiment_builder import ExperimentBuilder\n",
    "from data_providers import *\n",
    "import os\n",
    "from models.cnn import *\n",
    "from models.multilayer_perceptron import multi_layer_perceptron\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from globals import ROOT_DIR\n",
    "\n",
    "data = np.load(os.path.join(ROOT_DIR, 'data/founta_data.npy'))\n",
    "data = data[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1\n",
      "Processed 2\n",
      "Processed 3\n",
      "Processed 4\n",
      "Processed 5\n",
      "Processed 6\n",
      "Processed 7\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "for i in range(8):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    results = np.load(os.path.join(ROOT_DIR, 'data/bert_embeddings_{}.npz'.format(i)))\n",
    "    print(\"Processed {}\".format(i))\n",
    "    results = results['a']\n",
    "    results = results[()]\n",
    "    embeddings = {**results, **embeddings} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_keys = list(embeddings.keys())[0:2]\n",
    "test = np.array([embeddings[key] for key in embed_keys])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import *\n",
    "\n",
    "def fetch_model(model, embedding_level, input_shape_local, dropout):\n",
    "    if model == 'MLP':\n",
    "        return multi_layer_perceptron(input_shape_local)\n",
    "    if model == 'CNN':\n",
    "        if embedding_level == 'word':\n",
    "            return word_cnn(input_shape_local, dropout)\n",
    "        elif embedding_level == 'character':\n",
    "            return character_cnn(input_shape_local)\n",
    "    if model == 'DENSENET':\n",
    "        return densenet()\n",
    "    else:\n",
    "        raise ValueError(\"Model key not found {}\".format(embedding_level))\n",
    "\n",
    "\n",
    "def fetch_model_parameters(input_shape_local):\n",
    "    model_local = fetch_model(model='CNN',\n",
    "                            embedding_level='word',\n",
    "                            input_shape_local=input_shape_local,\n",
    "                            dropout=0.5)\n",
    "    criterion_local = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_local = torch.optim.Adam(model_local.parameters(), weight_decay=1e-4)\n",
    "    scheduler_local = optim.lr_scheduler.CosineAnnealingLR(optimizer_local, T_max=100, eta_min=0.0001)\n",
    "    return model_local, criterion_local, optimizer_local, scheduler_local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(os.path.join(ROOT_DIR, 'data/founta_data.csv'), header='infer', index_col=0, squeeze=True).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99799"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building basic block of Convolutional Network using input shape torch.Size([2, 768, 20])\n",
      "Block is built, output volume is torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "model, criterion, optimizer, _ = fetch_model_parameters(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "import tqdm\n",
    "\n",
    "device = torch.device('cpu')\n",
    "train_stats = OrderedDict()\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_stats = defaultdict(list)\n",
    "    with tqdm.tqdm(total=len(train_data)) as pbar_train:  # create a progress bar for training\n",
    "        for idx, (x, y) in enumerate(train_data):  # get data batches\n",
    "            run_train_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # take a training iter step\n",
    "            pbar_train.update(1)\n",
    "            pbar_train.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['train_loss'][-1],\n",
    "                                                                               epoch_stats['train_acc'][-1]))\n",
    "\n",
    "#     with tqdm.tqdm(total=len(valid_data)) as pbar_val:  # create a progress bar for validation\n",
    "#         for x, y in valid_data:  # get data batches\n",
    "#             run_evaluation_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # run a validation iter\n",
    "#             pbar_val.update(1)  # add 1 step to the progress bar\n",
    "#             pbar_val.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['valid_loss'][-1],\n",
    "#                                                                              epoch_stats['valid_acc'][-1]))\n",
    "     \n",
    "    \n",
    "    \n",
    "#     save_model(model, '', 'testing', epoch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(x):\n",
    "    embedding_list = []\n",
    "    count = 0\n",
    "    filename_count = 0\n",
    "    results = {}\n",
    "    for key, value in x.items():\n",
    "        embedding = embeddings[value['id']]\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(\"On {}\".format(count))\n",
    "            \n",
    "        if count % 10000 == 0:\n",
    "            filepath = os.path.join(ROOT_DIR, 'data/p_bert_embedding_{}.npz'.format(filename_count))\n",
    "            np.savez(filepath, a=results)\n",
    "            results = {}\n",
    "            filename_count += 1\n",
    "            print(\"on {}\".format(count))\n",
    "                    \n",
    "         # trim if too large\n",
    "        if len(embedding) > 17:\n",
    "            embedding = embedding[:17]\n",
    "    \n",
    "        if len(embedding) < 17:\n",
    "            diff = 17 - len(embedding)\n",
    "            embedding += [generate_random_embedding(768) for _ in range(diff)]        \n",
    "        \n",
    "        results[value['id']] = embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = get_embeddings(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "bert_embedding = BertEmbedding()\n",
    "start_ptr = 0\n",
    "rate = 100\n",
    "end_ptr = start_ptr + rate\n",
    "# results = np.load(os.path.join(ROOT_DIR, 'data/bert_embeddings.npz'))\n",
    "# results = results[()]\n",
    "results = {}\n",
    "item_count = start_ptr\n",
    "while(start_ptr <= len(tweet_text)):\n",
    "    \n",
    "    raw_results = bert_embedding(tweet_text[start_ptr:end_ptr])\n",
    "    for item in raw_results:\n",
    "        results[tweet_ids[item_count]] = item[1]\n",
    "        item_count += 1 \n",
    "        \n",
    "    print(\"Total items processed: {}\".format(item_count))\n",
    "    np.savez_compressed(os.path.join(ROOT_DIR, 'data/bert_embeddings'), results)\n",
    "    start_ptr += rate\n",
    "    end_ptr += rate \n",
    "print(\"End time: {}\".format((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = np.load(os.path.join(ROOT_DIR, 'data/bert_embeddings.npz'))\n",
    "# results = results[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(os.path.join(ROOT_DIR,'data/bert_embeddings.npz'))\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(os.path.join(ROOT_DIR, 'data/bert_embeddings.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data = {}\n",
    "for i, result in enumerate(results):\n",
    "    if i > 10:\n",
    "        break\n",
    "    embedding = result[1]\n",
    "    \n",
    "    # trim if too large\n",
    "    if len(embedding) > 17:\n",
    "        embedding = embedding[:17]\n",
    "    \n",
    "    if len(embedding) < 17:\n",
    "        diff = 17 - len(embedding)\n",
    "        embedding += [generate_random_embedding(768) for _ in range(diff)]\n",
    "\n",
    "    embedding_data[tweet_ids[i]] = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
