{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from globals import ROOT_DIR\n",
    "from data_providers import TextDataProvider\n",
    "import argparse\n",
    "import configparser\n",
    "from torch import optim\n",
    "from experiment_builder import ExperimentBuilder\n",
    "from data_providers import *\n",
    "import os\n",
    "from models.cnn import *\n",
    "from models.multilayer_perceptron import multi_layer_perceptron\n",
    "import tweepy\n",
    "from text_utils import *\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "path_data = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_DATA'])\n",
    "path_labels = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_LABELS'])\n",
    "from models.model_pytorch import TransformerModel, load_openai_pretrained_model, DEFAULT_CONFIG, DoubleHeadModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data/founta_data.npy'\n",
    "data = np.load(os.path.join(ROOT_DIR, path_data))\n",
    "data = data[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_feature_embeddings(x_embed, key='embedding'):\n",
    "    if key == 'tokens': #  for tdidf\n",
    "        return [' '.join(x[key]) for x in x_embed]\n",
    "    return [x[key] for x in x_embed]\n",
    "\n",
    "def process_outputs(outputs, experiment_flag=1):\n",
    "    \"\"\"\n",
    "    Cleans text, creates context tweets for reply experiment, and tokenizes\n",
    "    :param outputs: tweet data / label\n",
    "    :param experiment_flag: denotes what round of experiments this is, 1) tweet, 2) tweet + context tweet 3) reply net\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    replies = np.load(os.path.join(ROOT_DIR, 'data/reply_data.npy'))\n",
    "    replies = replies[()]\n",
    "\n",
    "    outputs_processed = []\n",
    "    for output in outputs:\n",
    "        # add context tweet\n",
    "        status_id = str(output['in_reply_to_status_id'])\n",
    "        if status_id in replies:\n",
    "            output['context_tweet'] = replies[status_id]\n",
    "        else:\n",
    "            output['context_tweet'] = ' '.join([' '] * TWEET_SENTENCE_SIZE)  # will be a random embedding\n",
    "\n",
    "        #  tokenize / clean\n",
    "        if experiment_flag == 1:\n",
    "            output['tokens'] = output['tweet'].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        elif experiment_flag == 2:\n",
    "            output['tokens'] = output['context_tweet'].translate(str.maketrans('', '', string.punctuation)).lower() + \\\n",
    "                               output['tweet'].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "        output['tokens'] = output['tokens'].split(' ')\n",
    "        outputs_processed.append(output)\n",
    "    return outputs_processed\n",
    "\n",
    "\n",
    "def extract_tweets(label_data, data, experiment_flag):\n",
    "    print(\"=== Extracting tweets from JSON ===\")\n",
    "    labels = []\n",
    "    labels_map = {'hateful': 0, 'abusive': 1, 'normal': 2, 'spam': 3}\n",
    "    error_count = 0\n",
    "    outputs = []\n",
    "\n",
    "    for key, value in data.items():\n",
    "\n",
    "        if int(value['id_str']) not in label_data:\n",
    "            error_count += 1\n",
    "            continue\n",
    "        output = {}\n",
    "        output['tweet'] = value['text']\n",
    "        output['label'] = labels_map[label_data[int(value['id_str'])]]\n",
    "        labels.append(output['label'])\n",
    "        output['retweet_count'] = value['retweet_count']\n",
    "        output['retweeted'] = int(value['retweeted'])\n",
    "        output['in_reply_to_status_id'] = value['in_reply_to_status_id'] if value[\n",
    "                                                                                'in_reply_to_status_id'] is not None else -1\n",
    "        output['favorite_count'] = value['favorite_count']\n",
    "        output['label_string'] = label_data[int(value['id_str'])]\n",
    "        outputs.append(output)\n",
    "    outputs_processed = process_outputs(outputs, experiment_flag)\n",
    "    return outputs_processed, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extracting tweets from JSON ===\n"
     ]
    }
   ],
   "source": [
    "label_data = pd.read_csv(os.path.join(ROOT_DIR,'data/labels.csv'), header='infer', index_col=0, squeeze=True).to_dict()\n",
    "outputs, labels = extract_tweets(label_data, data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sizes] Training set: 64.00%, Validation set: 16.00%, Test set: 20.00%\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = split_data(outputs, labels, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/ashemagalhaes/PycharmProjects/hate_speech/models/model/encoder_bpe_40000.json',\n",
       " '/Users/ashemagalhaes/PycharmProjects/hate_speech/models/model/vocab_40000.bpe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_path = os.path.join(ROOT_DIR,'models/model/vocab_40000.bpe')\n",
    "encoder_path = os.path.join(ROOT_DIR,'models/model/encoder_bpe_40000.json')\n",
    "\n",
    "encoder_path, bpe_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text_utils.TextEncoder at 0x1a4566e780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder = TextEncoder(encoder_path, bpe_path)\n",
    "text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = text_encoder.encoder\n",
    "n_vocab = len(text_encoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[616, 544, 246, 5958], [616, 544, 1359, 246, 5958]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder.encode(['this is a sentence', 'this is also a sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "x_train_enc = text_encoder.encode([x['tweet'] for x in x_train])\n",
    "x_valid_enc = text_encoder.encode([x['tweet'] for x in x_valid])\n",
    "x_test_enc = text_encoder.encode([x['tweet'] for x in x_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_data(batch_size, seed, x_train, y_train, x_valid, y_valid, x_test, y_test):\n",
    "    train_set = DataProvider(inputs=x_train, targets=y_train, seed=seed)\n",
    "    train_data_local = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   sampler=ImbalancedDatasetSampler(train_set))\n",
    "\n",
    "    valid_set = DataProvider(inputs=x_valid, targets=y_valid, seed=seed)\n",
    "    valid_data_local = torch.utils.data.DataLoader(valid_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    test_set = DataProvider(inputs=x_test, targets=y_test, seed=seed)\n",
    "    test_data_local = torch.utils.data.DataLoader(test_set,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  num_workers=2,\n",
    "                                                  shuffle=False)\n",
    "\n",
    "    return train_data_local, valid_data_local, test_data_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'x_train': x_train_enc, \n",
    "    'y_train': y_train, \n",
    "    'x_valid': x_valid_enc, \n",
    "    'y_valid': y_valid, \n",
    "     'x_test': x_test_enc, \n",
    "    'y_test': y_test, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = wrap_data(2048, 28, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_iter(model, device, optimizer, criterion, x, y, stats, experiment_key='train'):\n",
    "    \"\"\"\n",
    "    Receives the inputs and targets for the model and runs a training iteration. Returns loss and accuracy metrics.\n",
    "    :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n",
    "    :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n",
    "    :return: the loss and accuracy for this batch\n",
    "    \"\"\"\n",
    "    # sets model to training mode\n",
    "    # (in case batch normalization or other methods have different procedures for training and evaluation)\n",
    "    model.train()\n",
    "#     x = torch.tensor(x, dtype=torch.long).to(device)\n",
    "    x = [np.array(item) for item in x]\n",
    "    x = torch.FloatTensor(x)\n",
    "    print(torch.FloatTensor(x).shape)\n",
    "    y = y.to(device)\n",
    "    optimizer.zero_grad()  # set all weight grads from previous training iters to 0\n",
    "    out = model.forward(x)  # forward the data in the model\n",
    "    print(out.shape)\n",
    "    \n",
    "    out = F.max_pool1d(out, out.shape[-1])\n",
    "    out = out.view(out.shape[0], -1)\n",
    "    \n",
    "    out = nn.Linear(in_features=out.shape[1], \n",
    "                                    out_features=4,\n",
    "                                    bias=False)(out)     \n",
    "    print(out.shape)\n",
    "    \n",
    "    \n",
    "    # loss = F.cross_entropy(input=out, target=y)  # compute loss\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()  # backpropagate to compute gradients for current iter loss\n",
    "\n",
    "    optimizer.step()  # update network parameters\n",
    "    _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n",
    "    accuracy = np.mean(list(predicted.eq(y.data).cpu()))  # compute accuracy\n",
    "    stats['{}_acc'.format(experiment_key)].append(accuracy)\n",
    "    stats['{}_loss'.format(experiment_key)].append(loss.data.detach().cpu().numpy())\n",
    "\n",
    "# def run_evaluation_iter(model, device, optimizer, criterion, x, y, stats, experiment_key='valid'):\n",
    "#     \"\"\"\n",
    "#     Receives the inputs and targets for the model and runs an evaluation iterations. Returns loss and accuracy metrics.\n",
    "#     :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n",
    "#     :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n",
    "#     :return: the loss and accuracy for this batch\n",
    "#     \"\"\"\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()  # sets the system to validation mode\n",
    "#         x = np.array(x)\n",
    "#         print(x)\n",
    "# #         x = x.to(device)\n",
    "# #         y = y.to(device)\n",
    "        \n",
    "#         out = model.forward(torch.FloatTensor(x))  # forward the data in the model\n",
    "       \n",
    "        \n",
    "#         loss = criterion(out, y)\n",
    "        \n",
    "#         # loss = F.cross_entropy(out, y)  # compute loss\n",
    "#         _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n",
    "        \n",
    "#         accuracy = np.mean(list(predicted.eq(y.data).cpu()))\n",
    "#         stats['{}_acc'.format(experiment_key)].append(accuracy)  # compute accuracy\n",
    "#         stats['{}_loss'.format(experiment_key)].append(loss.data.detach().cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_save_dir, model_save_name, model_idx):\n",
    "    \"\"\"\n",
    "    Save the network parameter state and current best val epoch idx and best val accuracy.\n",
    "    :param model_save_name: Name to use to save model without the epoch index\n",
    "    :param model_idx: The index to save the model with.\n",
    "    :param best_validation_model_idx: The index of the best validation model to be stored for future use.\n",
    "    :param best_validation_model_acc: The best validation accuracy to be stored for use at test time.\n",
    "    :param model_save_dir: The directory to store the state at.\n",
    "    :param state: The dictionary containing the system state.\n",
    "\n",
    "    \"\"\"\n",
    "    # Save state each epoch\n",
    "    path = os.path.join(model_save_dir, \"{}_{}\".format(model_save_name, str(model_idx)))\n",
    "    torch.save(model.state_dict(), f=path)\n",
    "    \n",
    "\n",
    "def load_model(model, model_save_dir, model_save_name, model_idx):\n",
    "    \"\"\"\n",
    "    Load the network parameter state and the best val model idx and best val acc to be compared with the future val accuracies, in order to choose the best val model\n",
    "    :param model_save_dir: The directory to store the state at.\n",
    "    :param model_save_name: Name to use to save model without the epoch index\n",
    "    :param model_idx: The index to save the model with.\n",
    "    \"\"\"\n",
    "    path = os.path.join(model_save_dir, \"{}_{}\".format(model_save_name, str(model_idx)))\n",
    "    checkpoint = torch.load(f=path)\n",
    "    # freeze parameters\n",
    "    model.load_state_dict(checkpoint)\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (4) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-f99d55378887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar_train\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# create a progress bar for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# get data batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mrun_train_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_stats\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take a training iter step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#             pbar_train.update(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#             pbar_train.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['train_loss'][-1],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-141-b3d431563300>\u001b[0m in \u001b[0;36mrun_train_iter\u001b[0;34m(model, device, optimizer, criterion, x, y, stats, experiment_key)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set all weight grads from previous training iters to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# forward the data in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/hate_speech/models/model_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mtask_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/hate_speech/models/model_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/hate_speech/models/model_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/hate_speech/models/model_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/hate_speech/models/model_pytorch.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, q, k, v)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# XD: self.b may be larger than w, so we need to crop it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (4) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "import tqdm\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-4)\n",
    "device = torch.device('cpu')\n",
    "train_stats = OrderedDict()\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_stats = defaultdict(list)\n",
    "    with tqdm.tqdm(total=len(train_data)) as pbar_train:  # create a progress bar for training\n",
    "        for idx, (x, y) in enumerate(train_data):  # get data batches\n",
    "            run_train_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # take a training iter step\n",
    "#             pbar_train.update(1)\n",
    "#             pbar_train.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['train_loss'][-1],\n",
    "#                                                                                epoch_stats['train_acc'][-1]))\n",
    "\n",
    "#     with tqdm.tqdm(total=len(valid_data)) as pbar_val:  # create a progress bar for validation\n",
    "#         for x, y in valid_data:  # get data batches\n",
    "#             run_evaluation_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # run a validation iter\n",
    "#             pbar_val.update(1)  # add 1 step to the progress bar\n",
    "#             pbar_val.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['valid_loss'][-1],\n",
    "#                                                                              epoch_stats['valid_acc'][-1]))\n",
    "     \n",
    "    \n",
    "    \n",
    "#     save_model(model, '', 'testing', epoch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n"
     ]
    }
   ],
   "source": [
    "model = DoubleHeadModel(DEFAULT_CONFIG, len(encoder),'multiple_choice',40990, 4)\n",
    "load_openai_pretrained_model(model.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_embd': 768,\n",
       " 'n_head': 12,\n",
       " 'n_layer': 12,\n",
       " 'embd_pdrop': 0.1,\n",
       " 'attn_pdrop': 0.1,\n",
       " 'resid_pdrop': 0.1,\n",
       " 'afn': 'gelu',\n",
       " 'clf_pdrop': 0.1,\n",
       " 'n_class': 4}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
