{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from comet_ml import Experiment\n",
    "import argparse\n",
    "import configparser\n",
    "from torch import optim\n",
    "\n",
    "from experiment_builder import ExperimentBuilder\n",
    "from globals import ROOT_DIR\n",
    "from data_providers import *\n",
    "import os\n",
    "\n",
    "from models.fc_linear_tdidf import fc_linear_tdidf\n",
    "from models.cnn import *\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/80k_tweets.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['DEFAULT']['PATH_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(embedding_key, embedding_level_key, seed):\n",
    "    path_data = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_DATA'])\n",
    "    path_labels = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_LABELS'])\n",
    "    data_provider = TextDataProvider(path_data, path_labels)\n",
    "    if embedding_level_key == 'word':\n",
    "        output = data_provider.generate_word_level_embeddings(embedding_key, seed)\n",
    "    elif embedding_level_key == 'char':\n",
    "        output = data_provider.generate_char_level_embeddings(seed)\n",
    "    else:\n",
    "        output = data_provider.generate_tdidf_embeddings(seed)\n",
    "\n",
    "    if True:\n",
    "        print(\"[Sizes] Training set: {}, Validation set: {}, Test set: {}\".format(len(output['x_train']),\n",
    "                                                                                  len(output['x_valid']),\n",
    "                                                                                  len(output['x_test'])))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extracting annotations ===\n",
      "=== Extracting tweets from JSON ===\n",
      "[Stats] Removed 3/58358 labels\n",
      "[Stats] Average tweet length is 17 words\n",
      "[Stats] Average tweet length is 121 characters\n",
      "[Stats] Average favorite count is 15\n",
      "[Stats] Average retweet count is 146\n",
      "[Stats] Average follower count is 710\n",
      "[Sizes] Training set: 64.00%, Validation set: 16.00%, Test set: 20.00%\n",
      "[Model] Using fasttext embeddings\n",
      "[Sizes] Training set: 64.00%, Validation set: 16.00%, Test set: 20.00%\n",
      "[Sizes] Training set: 37348, Validation set: 9338, Test set: 11672\n"
     ]
    }
   ],
   "source": [
    "data = extract_data('fasttext','word', 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_data(batch_size, seed, x_train, y_train, x_valid, y_valid, x_test, y_test):\n",
    "    train_set = DataProvider(inputs=x_train, targets=y_train, seed=seed)\n",
    "    train_data_local = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   sampler=ImbalancedDatasetSampler(train_set))\n",
    "\n",
    "    valid_set = DataProvider(inputs=x_valid, targets=y_valid, seed=seed)\n",
    "    valid_data_local = torch.utils.data.DataLoader(valid_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    test_set = DataProvider(inputs=x_test, targets=y_test, seed=seed)\n",
    "    test_data_local = torch.utils.data.DataLoader(test_set,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  num_workers=2,\n",
    "                                                  shuffle=False)\n",
    "\n",
    "    return train_data_local, valid_data_local, test_data_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = wrap_data(64, 28, **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 3, 2, 2, 3, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 1, 2, 3, 2,\n",
      "        2, 2, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_data:  # sample batch\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 3, 2, 2, 3, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 1, 2, 3, 2,\n",
      "        2, 2, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_data:  # sample batch\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
