{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from globals import ROOT_DIR\n",
    "from data_providers import TextDataProvider\n",
    "import configparser\n",
    "import argparse\n",
    "import configparser\n",
    "from torch import optim\n",
    "from experiment_builder import ExperimentBuilder\n",
    "from data_providers import *\n",
    "import os\n",
    "from models.cnn import *\n",
    "from models.multilayer_perceptron import multi_layer_perceptron\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "path_data = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_DATA'])\n",
    "path_labels = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_LABELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', \n",
    "#            'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', \n",
    "#            'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', \n",
    "#            'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', \n",
    "#            'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])\n",
    "\n",
    "def extract_tweets(data, filename, subset=None):\n",
    "    start = time.time()\n",
    "    print(\"=== Extracting tweets from JSON ===\")\n",
    "    tweets = []\n",
    "    labels = []\n",
    "    line_count = 0\n",
    "    labels_map = {'hateful': 0, 'abusive': 1, 'normal': 2, 'spam': 3}\n",
    "    error_count = 0\n",
    "    outputs = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if subset is not None and line_count >= subset:\n",
    "                break\n",
    "            obj = json.loads(line)\n",
    "            if data[obj['id_str']] not in labels_map:\n",
    "                error_count += 1\n",
    "                continue\n",
    "            \n",
    "            output = {}\n",
    "            output['text'] = obj['text']\n",
    "            output['label'] = labels_map[data[obj['id_str']]]\n",
    "            labels.append(output['label'])\n",
    "            output['retweet_count'] = obj['retweet_count']\n",
    "            output['retweeted'] = int(obj['retweeted'])\n",
    "            output['in_reply_to_status_id'] = obj['in_reply_to_status_id'] if obj['in_reply_to_status_id'] is not None else -1\n",
    "            output['favorite_count'] = obj['favorite_count']\n",
    "            output['label_string'] = data[obj['id_str']]\n",
    "            outputs.append(output)\n",
    "            \n",
    "    print(\"Total time {}\".format((time.time() - start)/60))\n",
    "    return outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(filename):\n",
    "    print(\"=== Extracting annotations ===\")\n",
    "    data = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            data[row['tweet_id']] = row['maj_label']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extracting annotations ===\n",
      "=== Extracting tweets from JSON ===\n",
      "Total time 0.04245690107345581\n"
     ]
    }
   ],
   "source": [
    "path_data = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_DATA'])\n",
    "path_labels = os.path.join(ROOT_DIR, config['DEFAULT']['PATH_LABELS'])\n",
    "data = extract_labels(path_labels)\n",
    "outputs, labels = extract_tweets(data, path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[848960211155111936,\n",
       " 848683093322018817,\n",
       " 847652506372984835,\n",
       " 848974465681641472,\n",
       " 850153748353646594,\n",
       " 848644610108919808,\n",
       " 850090043423281152,\n",
       " 850450851084857345,\n",
       " 848898137888620544,\n",
       " 848738111378956288,\n",
       " 848593367630045185,\n",
       " 850354717544914944,\n",
       " 847870832185663488,\n",
       " 849401446097440768,\n",
       " 850758182398021633,\n",
       " 848271946362089473,\n",
       " 849126476309864448,\n",
       " 849159076995112961,\n",
       " 848682175465754627,\n",
       " 849960037313392642,\n",
       " 850798998218842114,\n",
       " 846965053240807424,\n",
       " 850740104956186625,\n",
       " 849362962452291586,\n",
       " 849568312061083648,\n",
       " 849078728823123968,\n",
       " 847892319672184832,\n",
       " 850196399513718785,\n",
       " 850760996218179584,\n",
       " 848840116214784001,\n",
       " 849300802795687937,\n",
       " 849585722680102913,\n",
       " 848627032330125313,\n",
       " 848340674533523456,\n",
       " 850566695295082497,\n",
       " 849679114416115714,\n",
       " 850366375159791616,\n",
       " 850294273337692160,\n",
       " 849091192105172992,\n",
       " 847971465043468288,\n",
       " 846841493952319489,\n",
       " 847873050439766016,\n",
       " 847560758888206337,\n",
       " 785661160200732672,\n",
       " 848412362918871040,\n",
       " 849434658970492928,\n",
       " 850446173605441537,\n",
       " 850162885800087552,\n",
       " 848957620149002240,\n",
       " 850039169720209409,\n",
       " 848400173831077888,\n",
       " 849799533026435072,\n",
       " 849920292763860996,\n",
       " 849024167571632128,\n",
       " 848044244522684416,\n",
       " 848880183629185024,\n",
       " 850269313839714306,\n",
       " 850213615835652096,\n",
       " 850378772855631872,\n",
       " 849544695894224896,\n",
       " 850244253225701376,\n",
       " 848889343062179840,\n",
       " 847131730461032448,\n",
       " 849071463529414656,\n",
       " 849408745536798720,\n",
       " 848663028027371520,\n",
       " 847790742957416448,\n",
       " 848707285786513410,\n",
       " 850353073331593217,\n",
       " 848608337696616448,\n",
       " 849699080318181376,\n",
       " 848006507329331201,\n",
       " 850025399174213633,\n",
       " 848760869722783744,\n",
       " 849557490446553089,\n",
       " 850157175339200513,\n",
       " 848506701149896704,\n",
       " 850807724065660928,\n",
       " 848034644842790914,\n",
       " 847964812449423360,\n",
       " 850498765957996548,\n",
       " 847461171439443968,\n",
       " 847700014511955968,\n",
       " 848196482058604544,\n",
       " 849726315771162626,\n",
       " 850015100748656640,\n",
       " 848920936866873345,\n",
       " 850572535221686273,\n",
       " 850633636785401856,\n",
       " 848665106783363073,\n",
       " 850371369221193730,\n",
       " 848872970420224000,\n",
       " 847875763097354240,\n",
       " 850210512763629569,\n",
       " 849382846661890048,\n",
       " 848541564620206080,\n",
       " 847107445755297792,\n",
       " 847565980452634625,\n",
       " 849834228556509186,\n",
       " 850450284203659269,\n",
       " 850005463529701377,\n",
       " 850051060429410306,\n",
       " 848230183102545920,\n",
       " 849567323119910912,\n",
       " 848036393272176640,\n",
       " 849319897293348864,\n",
       " 849425934218387456,\n",
       " 848533658491211777,\n",
       " 847705274303434752,\n",
       " 849305839831846915,\n",
       " 847590123512500225,\n",
       " 849617388173656067,\n",
       " 850174604861743104,\n",
       " 849977775293333504,\n",
       " 847743140299550721,\n",
       " 850133834893021186,\n",
       " 850535197275676672,\n",
       " 849713493104365568,\n",
       " 850394201191718912,\n",
       " 848333328591855616,\n",
       " 847635440928645120,\n",
       " 849811473652121600,\n",
       " 850371162102267904,\n",
       " 848055921171349504,\n",
       " 850517878402973696,\n",
       " 847108251036479488,\n",
       " 848880186644987904,\n",
       " 848769243302682624,\n",
       " 847639938434609152,\n",
       " 848753190753501184,\n",
       " 850426132914745344,\n",
       " 850472605471698944,\n",
       " 850816203039936512,\n",
       " 849115385831931904,\n",
       " 849129851495821313,\n",
       " 848203201094483972,\n",
       " 849298189077401601,\n",
       " 849733483236696064,\n",
       " 850074406067908608,\n",
       " 849096697481502724,\n",
       " 849717248294088705,\n",
       " 850362493348261888,\n",
       " 850685199214096384,\n",
       " 849638762762035201,\n",
       " 848294941482766337,\n",
       " 848364598361292800,\n",
       " 848938799367376896,\n",
       " 849407263169183745,\n",
       " 850160022470279173,\n",
       " 849950950722871296,\n",
       " 849649588147560450,\n",
       " 847860422950703104,\n",
       " 847743873908527105,\n",
       " 849280748200841217,\n",
       " 850354213867593728,\n",
       " 849391286025150465,\n",
       " 848491527080947712,\n",
       " 847270189171228672,\n",
       " 848464325555531776,\n",
       " 849852164872777729,\n",
       " 847648949720694786,\n",
       " 848193914578190336,\n",
       " 850475111157293059,\n",
       " 849534433778642944,\n",
       " 847848391992381444,\n",
       " 850531027604824064,\n",
       " 849331430572294148,\n",
       " 849359294172626944,\n",
       " 848770195187421184,\n",
       " 850456087689965568,\n",
       " 849201722769780737,\n",
       " 849394809928372228,\n",
       " 847813222476460033,\n",
       " 850770734611910656,\n",
       " 848176795237195780,\n",
       " 848287494038708224,\n",
       " 849094046106738688,\n",
       " 850240885472100356,\n",
       " 847631367550533632,\n",
       " 746405075489263616,\n",
       " 847686407820722176,\n",
       " 850647651632775169,\n",
       " 848240830582226946,\n",
       " 849106320112455680,\n",
       " 849310644503556097,\n",
       " 849051136309035012,\n",
       " 849010460150071297,\n",
       " 847818926750937088,\n",
       " 849833180194418688,\n",
       " 848526986607812608,\n",
       " 847586090319888385,\n",
       " 847724529858166786,\n",
       " 849307152426704897,\n",
       " 849645724098867200,\n",
       " 847621648794517504,\n",
       " 848210623188127745,\n",
       " 848503689585274880,\n",
       " 848868481567031296,\n",
       " 850194686929018880,\n",
       " 847778684513779712,\n",
       " 849034875319365633,\n",
       " 849277342979682304,\n",
       " 850502836634894336,\n",
       " 847538948247343105,\n",
       " 850710593761927168,\n",
       " 850127430757097472,\n",
       " 849018306681896960,\n",
       " 849743853083086850,\n",
       " 849561635710783491,\n",
       " 848486026230120448,\n",
       " 850104481459077121,\n",
       " 846713578963062785,\n",
       " 849268102332387328,\n",
       " 850015915609640960,\n",
       " 850400587455791104,\n",
       " 849688632697008137,\n",
       " 848769861173993473,\n",
       " 848238552655831041,\n",
       " 849322922783236096,\n",
       " 847520509218750464,\n",
       " 850764992727191552,\n",
       " 848470040521433088,\n",
       " 847961713123106817,\n",
       " 850710574463954944,\n",
       " 848069665167470593,\n",
       " 848252315693756416,\n",
       " 848590767056715776,\n",
       " 850463896775401473,\n",
       " 847552930626510848,\n",
       " 849494548627763200,\n",
       " 850207271070056449,\n",
       " 847567648074452992,\n",
       " 849679243365810176,\n",
       " 850281176749232128,\n",
       " 848355345428828160,\n",
       " 850094956094128129,\n",
       " 849986027418771456,\n",
       " 848612364400418823,\n",
       " 848887089999392769,\n",
       " 849026716941131776,\n",
       " 849811741215080449,\n",
       " 849945064541433857,\n",
       " 848288283809521667,\n",
       " 849415589714157568,\n",
       " 848204870876356608,\n",
       " 849286234203664385,\n",
       " 847943684486311937,\n",
       " 848752316085940224,\n",
       " 850793366287732737,\n",
       " 849056825018155008,\n",
       " 849581431806459904,\n",
       " 849101068529266690,\n",
       " 849609143833022465,\n",
       " 848224132730937346,\n",
       " 850264149086973952,\n",
       " 847792024447307776,\n",
       " 848131608234295298,\n",
       " 848366648780369925,\n",
       " 850450373919813632,\n",
       " 847689853772767232,\n",
       " 848552237861359620,\n",
       " 847414608876797952,\n",
       " 849148417414766592,\n",
       " 849624796685975555,\n",
       " 849495183813201920,\n",
       " 850802589172158466,\n",
       " 847560284709322752,\n",
       " 849081551363223554,\n",
       " 847523584952094721,\n",
       " 849813404571357184,\n",
       " 848446785811042304,\n",
       " 848817257992138752,\n",
       " 848397255572807680,\n",
       " 847837480103563264,\n",
       " 850685634427670529,\n",
       " 848236729173770241,\n",
       " 850692573026897920,\n",
       " 849457570708422657,\n",
       " 847494713766793216,\n",
       " 849352649111519232,\n",
       " 848963618272096257,\n",
       " 849996206793162752,\n",
       " 848727017130311680,\n",
       " 847498058652721152,\n",
       " 849260009477332992,\n",
       " 848857910297980928,\n",
       " 847644379409899522,\n",
       " 850337771982114817,\n",
       " 847565665284370433,\n",
       " 848177366610432001,\n",
       " 849179419918848000,\n",
       " 848972483503964160,\n",
       " 848254931912077314,\n",
       " 848703664416067584,\n",
       " 848452498058883073,\n",
       " 847976875511205888,\n",
       " 849280575223599105,\n",
       " 848828238189252608,\n",
       " 849400749054459904,\n",
       " 850186543998357508,\n",
       " 850509649723891712,\n",
       " 849999260389081088,\n",
       " 850723490554675200,\n",
       " 849984214682525696,\n",
       " 848033656987729921,\n",
       " 849085613479522305,\n",
       " 848382515538571264,\n",
       " 848190424338513922,\n",
       " 850205970370150400,\n",
       " 847963071519760385,\n",
       " 847862788806639617,\n",
       " 848649778758131713,\n",
       " 848210271575396354,\n",
       " 848617183588618241,\n",
       " 848797710178148354,\n",
       " 850426175226818560,\n",
       " 848784776936824832,\n",
       " 847715868150607874,\n",
       " 850077816620240896,\n",
       " 848532502553796608,\n",
       " 848442048655093760,\n",
       " 848011569141137408,\n",
       " 847589632632082433,\n",
       " 847478532460687361,\n",
       " 850842526328270848,\n",
       " 850361666365685761,\n",
       " 848263644810887168,\n",
       " 849161932565344256,\n",
       " 848882619467132928,\n",
       " 849645483807080453,\n",
       " 847413475189989376,\n",
       " 849436709037244416,\n",
       " 847459751336267776,\n",
       " 847711222497554432,\n",
       " 847537705705779200,\n",
       " 850538354546536448,\n",
       " 849265368128290817,\n",
       " 849461752723058691,\n",
       " 848745295215157251,\n",
       " 848735047142297601,\n",
       " 849119962559991808,\n",
       " 850591184535924736,\n",
       " 849991610477813760,\n",
       " 847712374614179842,\n",
       " 847443406041239553,\n",
       " 849706964842147841,\n",
       " 847906788515209216,\n",
       " 849511945766150144,\n",
       " 848872191068430342,\n",
       " 849514945314160640,\n",
       " 848597949152206848,\n",
       " 849353226172366849,\n",
       " 848010490647379969,\n",
       " 848955832998010881,\n",
       " 848532015452479489,\n",
       " 848426949143781376,\n",
       " 849122516832591872,\n",
       " 827146768525688832,\n",
       " 848840039777705984,\n",
       " 849720633365643264,\n",
       " 847994272099950593,\n",
       " 850165695031779328,\n",
       " 850354524598480898,\n",
       " 850420165695213569,\n",
       " 843431442550087681,\n",
       " 847627959158456320,\n",
       " 850114304225529856,\n",
       " 850709175193620480,\n",
       " 848519303968239616,\n",
       " 850366884113416193,\n",
       " 850756761015472129,\n",
       " 847435163143454723,\n",
       " 850762949056761856,\n",
       " 847528918773096449,\n",
       " 848951919448133632,\n",
       " 849077897239429122,\n",
       " 847460373519257602,\n",
       " 850762495677657089,\n",
       " 850009027102879744,\n",
       " 850343714774016000,\n",
       " 849273972764160000,\n",
       " 848243747951439872,\n",
       " 848347395394088961,\n",
       " 847542924292354049,\n",
       " 848665072444616705,\n",
       " 850175048212250626,\n",
       " 848545753756774400,\n",
       " 850321301860360195,\n",
       " 849843398143991808,\n",
       " 848056331139522560,\n",
       " 848148114468999168,\n",
       " 849598735311044609,\n",
       " 848689076446396417,\n",
       " 848611223805538304,\n",
       " 849125631765823488,\n",
       " 848880519458717698,\n",
       " 847952315222966272,\n",
       " 847522127213400065,\n",
       " 848429950432681984,\n",
       " 849050193257525248,\n",
       " 849446597935190017,\n",
       " 849420542314762241,\n",
       " 850048516076470272,\n",
       " 850138377315917825,\n",
       " 847865233880350720,\n",
       " 847934232978755584,\n",
       " 849693474983223296,\n",
       " 850005617595076609,\n",
       " 827714037764988928,\n",
       " 847581399611658240,\n",
       " 848581582478868480,\n",
       " 850006488714182660,\n",
       " 850485368944181249,\n",
       " 850773174929117184,\n",
       " 850179990197084161,\n",
       " 847918321299271680,\n",
       " 850024831085142016,\n",
       " 849844410200145920,\n",
       " 849915576365588481,\n",
       " 849789622490210306,\n",
       " 847678384054206465,\n",
       " 850173927032844289,\n",
       " 849998104384372737,\n",
       " 850466431263272960,\n",
       " 849175162868031490,\n",
       " 847164746767978501,\n",
       " 849573282324131840,\n",
       " 850610072946397185,\n",
       " 850027534708346880,\n",
       " 850779582277984256,\n",
       " 849005594501689346,\n",
       " 846742165959180288,\n",
       " 849938512338202624,\n",
       " 849606173527506945,\n",
       " 850049811172794368,\n",
       " 850155121497559040,\n",
       " 850680287705124870,\n",
       " 849389922112995328,\n",
       " 850466429438750720,\n",
       " 849347243228499968,\n",
       " 847631322772144128,\n",
       " 849446964563509250,\n",
       " 848414181007151104,\n",
       " 849245224878706690,\n",
       " 849371819337551876,\n",
       " 850173025190158337,\n",
       " 847762071844515840,\n",
       " 849074918155223040,\n",
       " 848219027659010051,\n",
       " 849039254017761281,\n",
       " 848300816654061568,\n",
       " 847089838037876737,\n",
       " 850442982209855489,\n",
       " 847942942165803009,\n",
       " 850450047284260865,\n",
       " 849623419704487936,\n",
       " 848134975954313216,\n",
       " 849821367885332481,\n",
       " 847295042226077697,\n",
       " 850169340481609728,\n",
       " 850395245208416256,\n",
       " 849395944672120835,\n",
       " 847557671599394818,\n",
       " 847863609782939651,\n",
       " 849803025136979968,\n",
       " 847192152404897794,\n",
       " 848366239344930817,\n",
       " 848610526569439232,\n",
       " 850499219064356864,\n",
       " 848211134964408320,\n",
       " 850451167998029824,\n",
       " 849852544423784448,\n",
       " 847588965326626817,\n",
       " 848307515745902592,\n",
       " 850465182375608320,\n",
       " 847951864930996224,\n",
       " 848194791531843585,\n",
       " 850100382751707137,\n",
       " 848937946992574466,\n",
       " 849934444492455936,\n",
       " 849237671721480192,\n",
       " 849115145607434241,\n",
       " 848692475871080452,\n",
       " 850066722979803137,\n",
       " 849809315758211073,\n",
       " 849821967691653120,\n",
       " 849131188753223680,\n",
       " 849030277544497152,\n",
       " 849391064217776129,\n",
       " 849654699619962880,\n",
       " 850143871115948033,\n",
       " 847931075015913472,\n",
       " 849617698086682628,\n",
       " 849163316027109376,\n",
       " 847449842695655424,\n",
       " 849270838885068801,\n",
       " 849427644588470273,\n",
       " 848939615507685378,\n",
       " 848057631210078208,\n",
       " 850518661328654336,\n",
       " 849728396439556096,\n",
       " 850441741215739904,\n",
       " 847614601713770496,\n",
       " 849379669883457536,\n",
       " 850493113705656320,\n",
       " 848186568951177216,\n",
       " 848452616019259392,\n",
       " 849418364703449088,\n",
       " 850815650222059520,\n",
       " 847727698684264448,\n",
       " 848619041602375680,\n",
       " 848872744934666242,\n",
       " 850746233211592704,\n",
       " 849082150108442625,\n",
       " 849038556567875584,\n",
       " 849303284066156545,\n",
       " 847553379433951232,\n",
       " 849561143509217280,\n",
       " 849047058539573248,\n",
       " 849166387906064384,\n",
       " 848066561810194432,\n",
       " 850156614422343684,\n",
       " 847633313992916997,\n",
       " 847924543956148225,\n",
       " 848153860602507264,\n",
       " 848900524145614848,\n",
       " 849290388384907264,\n",
       " 850060546686808064,\n",
       " 847550062452461569,\n",
       " 847531173056311297,\n",
       " 850039117589118977,\n",
       " 848961779841585154,\n",
       " 850450430396166144,\n",
       " 847952145659908096,\n",
       " 849277753597755393,\n",
       " 848348258661543937,\n",
       " 850513537583771651,\n",
       " 849592766959157248,\n",
       " 850027811268173824,\n",
       " 847565731373907968,\n",
       " 848227406141939712,\n",
       " 849283851251789828,\n",
       " 844285021498359811,\n",
       " 848490075566391296,\n",
       " 850739193131216898,\n",
       " 850052990098710528,\n",
       " 848871504095981570,\n",
       " 848160947722235904,\n",
       " 849646001430425601,\n",
       " 847853842473426945,\n",
       " 849633901253283844,\n",
       " 850125487099609088,\n",
       " 850207265894219776,\n",
       " 850141870470701057,\n",
       " 850176319975555074,\n",
       " 849683380484665345,\n",
       " 847510771458220032,\n",
       " 849306452539961345,\n",
       " 848728858421604352,\n",
       " 847944881817481216,\n",
       " 849329689592287233,\n",
       " 848748620455096320,\n",
       " 847594350817181696,\n",
       " 847636530151608321,\n",
       " 847466148081704960,\n",
       " 849398657212461058,\n",
       " 848630088396439552,\n",
       " 850755602259116032,\n",
       " 850181497399255040,\n",
       " 848842537544466433,\n",
       " 849874996050743298,\n",
       " 847121599564169216,\n",
       " 849277520369340418,\n",
       " 847736081583816704,\n",
       " 848470350539173892,\n",
       " 848971097177546757,\n",
       " 850387600665923584,\n",
       " 850565004910841857,\n",
       " 848075843222077442,\n",
       " 849695778780172292,\n",
       " 850772789384679424,\n",
       " 850098074819186693,\n",
       " 848627892540067841,\n",
       " 850572072292167680,\n",
       " 841764070957187073,\n",
       " 850408330258415618,\n",
       " 848362970711285760,\n",
       " 848926863909163009,\n",
       " 850037025071800320,\n",
       " 850070760731402240,\n",
       " 850315630179909632,\n",
       " 849162009740554240,\n",
       " 850643383517192192,\n",
       " 847533580519657472,\n",
       " 849792187554422784,\n",
       " 848858885821669377,\n",
       " 848958020788682752,\n",
       " 850513517010718721,\n",
       " 850530347813142529,\n",
       " 849946666383888384,\n",
       " 849078405685444613,\n",
       " 849024867471110146,\n",
       " 849456224726900740,\n",
       " 849681658588606465,\n",
       " 848976691141726208,\n",
       " 849998108092223488,\n",
       " 849427656424685568,\n",
       " 849964255046709250,\n",
       " 850461007814066177,\n",
       " 850315025726279681,\n",
       " 849274754834083840,\n",
       " 849290102706778112,\n",
       " 849089338440908800,\n",
       " 850366957270388737,\n",
       " 847588890257108992,\n",
       " 850125998280626176,\n",
       " 850089399446626304,\n",
       " 850508393487925253,\n",
       " 847950135334187008,\n",
       " 848983162311061504,\n",
       " 850191383029837825,\n",
       " 848932605957476352,\n",
       " 847766558520856578,\n",
       " 850491015395987456,\n",
       " 850486528946184193,\n",
       " 824772388793507844,\n",
       " 849849689054826496,\n",
       " 850360564819927042,\n",
       " 850079936744484864,\n",
       " 849949059674771456,\n",
       " 850130645242302468,\n",
       " 850044050543710209,\n",
       " 849152312945803264,\n",
       " 849420553861640192,\n",
       " 849710026579218432,\n",
       " 848136532519157760,\n",
       " 849941607679901696,\n",
       " 848631070199136256,\n",
       " 850205401681321984,\n",
       " 850436489590841344,\n",
       " 849626121159290880,\n",
       " 847425812370407428,\n",
       " 850511511009275904,\n",
       " 847302468530716672,\n",
       " 850602956428779520,\n",
       " 850432794270543872,\n",
       " 850332275141160964,\n",
       " 848446894359683072,\n",
       " 847625161914294273,\n",
       " 849189656692477952,\n",
       " 848378250522804224,\n",
       " 850793905083883520,\n",
       " 847694465036828673,\n",
       " 848744702354497536,\n",
       " 850093213599780864,\n",
       " 849241203061256194,\n",
       " 850559140795736064,\n",
       " 847590102700359680,\n",
       " 848691029922459649,\n",
       " 848489286655770625,\n",
       " 847505472722685952,\n",
       " 849444831483097088,\n",
       " 847671979113013248,\n",
       " 822805833792659456,\n",
       " 849035284440371200,\n",
       " 847505670236766208,\n",
       " 850168386114007050,\n",
       " 849126706459705344,\n",
       " 848729579497934848,\n",
       " 849388093450924032,\n",
       " 850116775400419328,\n",
       " 848992200713261064,\n",
       " 849568096822210560,\n",
       " 848303924721397761,\n",
       " 848613547487752192,\n",
       " 848641288886996992,\n",
       " 849076821232689152,\n",
       " 847437919413456896,\n",
       " 847478628866637824,\n",
       " 849026661127299073,\n",
       " 850175599780012032,\n",
       " 847615457708326915,\n",
       " 849022808155934720,\n",
       " 847887494997696512,\n",
       " 849222956693803008,\n",
       " 848990151388917760,\n",
       " 848017197704384513,\n",
       " 850698638917586946,\n",
       " 847413905886294018,\n",
       " 848771437406146561,\n",
       " 849304836633919488,\n",
       " 848708442470588416,\n",
       " 849305637129527298,\n",
       " 850699676760375296,\n",
       " 849516657785659392,\n",
       " 848723179157815296,\n",
       " 849695960791793664,\n",
       " 850729010522841088,\n",
       " 847534649488355329,\n",
       " 847927810694008832,\n",
       " 849016561574825987,\n",
       " 847953936766173184,\n",
       " 847914733026103297,\n",
       " 847625139214733312,\n",
       " 849372694638465024,\n",
       " 847324167745622016,\n",
       " 848222251665182720,\n",
       " 849300310891921409,\n",
       " 849752886674436096,\n",
       " 849452650676539396,\n",
       " 848205112405368833,\n",
       " 847492591620931585,\n",
       " 849064389546311680,\n",
       " 848374976356995072,\n",
       " 848857910297980928,\n",
       " 850010215550504962,\n",
       " 849055450834382850,\n",
       " 850504825179697152,\n",
       " 847640344371933184,\n",
       " 848938549210746880,\n",
       " 848655692256788480,\n",
       " 850354484756787201,\n",
       " 847811119200612354,\n",
       " 850476968063623169,\n",
       " 849984419997908993,\n",
       " 849032178340114432,\n",
       " 849699435001020416,\n",
       " 848183445566009344,\n",
       " 850058452785397761,\n",
       " 848818155497586688,\n",
       " 849364710285770752,\n",
       " 847417333219864576,\n",
       " 850654578475507712,\n",
       " 850181565254643714,\n",
       " 850129971981033472,\n",
       " 847585003617873920,\n",
       " 847573220417044480,\n",
       " 850097063052423170,\n",
       " 849451387662499844,\n",
       " 850318156509958146,\n",
       " 850429260238073857,\n",
       " 847833796116455424,\n",
       " 848754459089944576,\n",
       " 848910515829186562,\n",
       " 848675693890293764,\n",
       " 848696052597313538,\n",
       " 849813939936481280,\n",
       " 850716784965459970,\n",
       " 849414647119843329,\n",
       " 847480720914354176,\n",
       " 848062590559203328,\n",
       " 848998227290591232,\n",
       " 849823333453529088,\n",
       " 850146126351261697,\n",
       " 850521905174065152,\n",
       " 848732992197480448,\n",
       " 848577969677316096,\n",
       " 848612611755266050,\n",
       " 850174462171516928,\n",
       " 847947982322487296,\n",
       " 849775816829534210,\n",
       " 849856056452816896,\n",
       " 848110553436307456,\n",
       " 846854703183020032,\n",
       " 848311302669950976,\n",
       " 849774724049719296,\n",
       " 847924574058663936,\n",
       " 847472419501559810,\n",
       " 848926673831645185,\n",
       " 850512194492145665,\n",
       " 850415658198327297,\n",
       " 848913713138618368,\n",
       " 848515508739682304,\n",
       " 848891537974886400,\n",
       " 849104008283275265,\n",
       " 848575525350105089,\n",
       " 848111515874058241,\n",
       " 849041498826043393,\n",
       " 847567227800834049,\n",
       " 849638650782601216,\n",
       " 850489072384712704,\n",
       " 848163548106694656,\n",
       " 847455180912181249,\n",
       " 850193902917255168,\n",
       " 847490221977387010,\n",
       " 847239149593673728,\n",
       " 848342146914680832,\n",
       " 847436194329833472,\n",
       " 849843752973856768,\n",
       " 850147751988006912,\n",
       " 848303371144511489,\n",
       " 850312543679778817,\n",
       " 848975420506742784,\n",
       " 847949049873416192,\n",
       " 849684342783844353,\n",
       " 848980128113623040,\n",
       " 850462726153437185,\n",
       " 849797941363695617,\n",
       " 849834590688731136,\n",
       " 850705435300704256,\n",
       " 849523631017402369,\n",
       " 850688752989220864,\n",
       " 850613924705714176,\n",
       " 848322924465573889,\n",
       " 847550516083216384,\n",
       " 850435753771495424,\n",
       " 847951804591738880,\n",
       " 848182548186484736,\n",
       " 849298840683524097,\n",
       " 849796981094592512,\n",
       " 850620723500646401,\n",
       " 849356063258402816,\n",
       " 850243669634424832,\n",
       " 849169415530840064,\n",
       " 850181799477039104,\n",
       " 659801754721255428,\n",
       " 849084751524892675,\n",
       " 848841694401495040,\n",
       " 847883824071626752,\n",
       " 848023619414437888,\n",
       " 850475339323244544,\n",
       " 848032336880992256,\n",
       " 847472838684495874,\n",
       " 850287808572866560,\n",
       " 850134188380618752,\n",
       " 848591315717804032,\n",
       " 849010382907650048,\n",
       " 849500668536770560,\n",
       " 848624975405883392,\n",
       " 848675025284673539,\n",
       " 849288796944211973,\n",
       " 847085090651852800,\n",
       " 849759253929832453,\n",
       " 847680295381778433,\n",
       " 847593660631965698,\n",
       " 847962443439460352,\n",
       " 850726742482464768,\n",
       " 848944287525945344,\n",
       " 850530654831955968,\n",
       " 849976707167768576,\n",
       " 847933528608313344,\n",
       " 849458641904316416,\n",
       " 847432558644125696,\n",
       " 850209059105980416,\n",
       " 848288361336807425,\n",
       " 850061499393552386,\n",
       " 848649679428624384,\n",
       " 848266355312807936,\n",
       " 850019429157044226,\n",
       " 849399727355568129,\n",
       " 850408620613292032,\n",
       " 848552465993781248,\n",
       " 849904309332344833,\n",
       " 849530247510982656,\n",
       " 850574788481384448,\n",
       " 847838235015467008,\n",
       " 849570844745449472,\n",
       " 850054910074683392,\n",
       " 849336596218368000,\n",
       " 849661755450064896,\n",
       " 849756773426708482,\n",
       " 847703816069763074,\n",
       " 850360293859315713,\n",
       " 848215005757673472,\n",
       " 849797266944741376,\n",
       " 848606026928721922,\n",
       " 848544088085417984,\n",
       " 848787005756649473,\n",
       " 848376816192507904,\n",
       " 850777950161166337,\n",
       " 849299318842560512,\n",
       " 848933429802618881,\n",
       " 850703362408554497,\n",
       " 848430951550136320,\n",
       " 850789412015398912,\n",
       " 847541283648225280,\n",
       " 849278426452119552,\n",
       " 850723509370327040,\n",
       " 849313591442501633,\n",
       " 849571883897024512,\n",
       " 850539475641843712,\n",
       " 850753180153651200,\n",
       " 848075526270992384,\n",
       " 849105174110937094,\n",
       " 849345514894225409,\n",
       " 848228798076211203,\n",
       " 850425293210886144,\n",
       " 849459229660516352,\n",
       " 849751859858472962,\n",
       " 848905259644628996,\n",
       " 850170533564035074,\n",
       " 849331065869225985,\n",
       " 847846370392145920,\n",
       " 850212605146783746,\n",
       " 849716766129364992,\n",
       " 850778668448321537,\n",
       " 847508012365262848,\n",
       " 848568486389587968,\n",
       " 850010217400152064,\n",
       " 850185921614016512,\n",
       " 850352674851741696,\n",
       " 850800045012201473,\n",
       " 847431344980238342,\n",
       " 849043842502471680,\n",
       " 849425979244249092,\n",
       " 849679831478304768,\n",
       " 850176351835496449,\n",
       " 849783765689880578,\n",
       " 850426386326183937,\n",
       " 847680305611788289,\n",
       " 848529014667055105,\n",
       " 850198708008263682,\n",
       " 849719868656033792,\n",
       " 847541963440111616,\n",
       " 850453158719520768,\n",
       " 848515249154162688,\n",
       " 848890523184238592,\n",
       " 847502105912856576,\n",
       " 849390071824470022,\n",
       " 850834346332368896,\n",
       " 850051205913092099,\n",
       " 848924548405899264,\n",
       " 850156926264422400,\n",
       " 847442649237934080,\n",
       " 849977493666893824,\n",
       " 850653285392330752,\n",
       " 848940782958637057,\n",
       " 850741559846940676,\n",
       " 850739258432380929,\n",
       " 848467786359767041,\n",
       " 848847622844686336,\n",
       " 848932437266759681,\n",
       " 848589261171335168,\n",
       " 847641350061379584,\n",
       " 849565591904059398,\n",
       " 850437065250676738,\n",
       " 848722731298435072,\n",
       " 848797865522585601,\n",
       " 847918553588170752,\n",
       " 849018073197805568,\n",
       " 847056211006631936,\n",
       " 850549044858556416,\n",
       " 848577823098929152,\n",
       " 847907456013545474,\n",
       " 849388746747383809,\n",
       " 848164410690609152,\n",
       " 847886382303465473,\n",
       " 848968708714147840,\n",
       " 850216567899947010,\n",
       " 849697128452681732,\n",
       " 849484567379677185,\n",
       " 849671190889320449,\n",
       " 839563764559134720,\n",
       " 847824321208885250,\n",
       " 850635000613527552,\n",
       " 848212879589421057,\n",
       " 850699627905110017,\n",
       " 849832746994290688,\n",
       " 849702736962703361,\n",
       " 850351032865624065,\n",
       " 847586944317964288,\n",
       " 849662937069490178,\n",
       " 850459098365796352,\n",
       " 850421314435371008,\n",
       " 849346488463478784,\n",
       " 846073877809782784,\n",
       " 850068883579031553,\n",
       " 849810206141931521,\n",
       " 848858594401411073,\n",
       " 848799253099053056,\n",
       " 848501682686369792,\n",
       " 849299555061563392,\n",
       " 850364845383876609,\n",
       " 849778712899977217,\n",
       " 848727517250953216,\n",
       " 848395495475118080,\n",
       " 840030701613391872,\n",
       " 848625949650419717,\n",
       " 849368617804341250,\n",
       " 849377868052402178,\n",
       " 849778711817666560,\n",
       " 848248603894308869,\n",
       " 848188276196466691,\n",
       " 849648984423641088,\n",
       " 850087312860094465,\n",
       " 850770493070114816,\n",
       " 848155868512133120,\n",
       " 847954648120127488,\n",
       " 847626998989979655,\n",
       " 847728171625701376,\n",
       " 848963376063565826,\n",
       " 850463672296030210,\n",
       " 849688097264738304,\n",
       " 848985317885476864,\n",
       " 848973167074963458,\n",
       " 848011052109398016,\n",
       " 848595221898285056,\n",
       " 849799302708965376,\n",
       " 849021422542442496,\n",
       " 848677072683888640,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_ids = [output['in_reply_to_status_id'] for output in outputs if output['in_reply_to_status_id'] != -1]\n",
    "status_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11934"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(status_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected tweets from tweepy \n",
    "# start_ptr = 11800\n",
    "# end_ptr = start_ptr + 100 \n",
    "# while(start_ptr <= len(status_ids)):\n",
    "#     print(\"Start ptr is at {}\".format(start_ptr))\n",
    "#     reply_tweets = api.statuses_lookup(status_ids[start_ptr:end_ptr],trim_user=True)\n",
    "    \n",
    "#     # load and save results each time \n",
    "#     replies = np.load(os.path.join(ROOT_DIR, 'data/reply_data.npy'))\n",
    "#     replies = replies[()]\n",
    "#     for i, reply_tweet in enumerate(reply_tweets):\n",
    "#         reply_tweet = reply_tweet._json\n",
    "#         replies[reply_tweet['id_str']] = reply_tweet['text']\n",
    "#     np.save(os.path.join(ROOT_DIR, 'data/reply_data.npy'), replies)\n",
    "    \n",
    "#     start_ptr += 100 \n",
    "#     end_ptr += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16608010725657785\n"
     ]
    }
   ],
   "source": [
    "replies = np.load(os.path.join(ROOT_DIR, 'data/reply_data.npy'))\n",
    "replies = replies[()]\n",
    "count = 0 \n",
    "# 0.16608010725657785 deleted... \n",
    "for status_id in status_ids:\n",
    "    if str(status_id) not in replies:\n",
    "        count += 1\n",
    "print(count / len(status_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e973eca47e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#verifies missing tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmissing_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatuses_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m847652506372984835\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrim_user\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmissing_tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "#verifies missing tweet \n",
    "# missing_tweet = api.statuses_lookup([847652506372984835],trim_user=True)\n",
    "# missing_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining tweets \n",
    "status_ids_fetched = []\n",
    "outputs_context = []\n",
    "for output in outputs:\n",
    "    status_id = str(output['in_reply_to_status_id'])\n",
    "    if status_id in replies:\n",
    "        output['reply_to_tweet_text'] = output['text'] + replies[status_id]\n",
    "    else:\n",
    "        output['reply_to_tweet_text'] = output['text'] + output['text']\n",
    "    outputs_context.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def tokenize(outpus):\n",
    "    key = 'reply_to_tweet_text'\n",
    "    outputs_processed = []\n",
    "    for output in outputs:\n",
    "        text = output[key]\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = text.split(' ')\n",
    "        output['tokens'] = tokens\n",
    "        outputs_processed.append(output)\n",
    "    return outputs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'fucks sake go away stupid anon — ^  https://t.co/8TQGyiKCVE',\n",
       " 'label': 1,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': 0,\n",
       " 'in_reply_to_status_id': -1,\n",
       " 'favorite_count': 0,\n",
       " 'label_string': 'abusive',\n",
       " 'reply_to_tweet_text': 'fucks sake go away stupid anon — ^  https://t.co/8TQGyiKCVEfucks sake go away stupid anon — ^  https://t.co/8TQGyiKCVE',\n",
       " 'tokens': ['fucks',\n",
       "  'sake',\n",
       "  'go',\n",
       "  'away',\n",
       "  'stupid',\n",
       "  'anon',\n",
       "  '—',\n",
       "  '',\n",
       "  '',\n",
       "  'httpstco8TQGyiKCVEfucks',\n",
       "  'sake',\n",
       "  'go',\n",
       "  'away',\n",
       "  'stupid',\n",
       "  'anon',\n",
       "  '—',\n",
       "  '',\n",
       "  '',\n",
       "  'httpstco8TQGyiKCVE']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_processed = tokenize(outputs_context)\n",
    "outputs_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sizes] Training set: 64.00%, Validation set: 16.00%, Test set: 20.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"#BravesAreBack let's go!!! #Braves #bravescountry @kapaya1234 you ready? Is the commute to SunTrust easier for you?\",\n",
       " 'label': 2,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': 0,\n",
       " 'in_reply_to_status_id': -1,\n",
       " 'favorite_count': 0,\n",
       " 'label_string': 'normal',\n",
       " 'reply_to_tweet_text': \"#BravesAreBack let's go!!! #Braves #bravescountry @kapaya1234 you ready? Is the commute to SunTrust easier for you?#BravesAreBack let's go!!! #Braves #bravescountry @kapaya1234 you ready? Is the commute to SunTrust easier for you?\",\n",
       " 'tokens': ['BravesAreBack',\n",
       "  'lets',\n",
       "  'go',\n",
       "  'Braves',\n",
       "  'bravescountry',\n",
       "  'kapaya1234',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'Is',\n",
       "  'the',\n",
       "  'commute',\n",
       "  'to',\n",
       "  'SunTrust',\n",
       "  'easier',\n",
       "  'for',\n",
       "  'youBravesAreBack',\n",
       "  'lets',\n",
       "  'go',\n",
       "  'Braves',\n",
       "  'bravescountry',\n",
       "  'kapaya1234',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'Is',\n",
       "  'the',\n",
       "  'commute',\n",
       "  'to',\n",
       "  'SunTrust',\n",
       "  'easier',\n",
       "  'for',\n",
       "  'you']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = split_data(outputs_processed, labels, 28)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_EMBED_DIM = 300\n",
    "TWITTER_EMBED_DIM = 400\n",
    "TWEET_SENTENCE_SIZE = 17*2 # 16 is average tweet token length\n",
    "TWEET_WORD_SIZE = 20 # selected by histogram of tweet counts\n",
    "FASTTEXT_EMBED_DIM = 300\n",
    "EMBED_DIM = 200\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "def generate_random_embedding(embed_dim):\n",
    "    return np.random.normal(scale=0.6, size=(embed_dim,))\n",
    "\n",
    "\n",
    "# embeds tokens! \n",
    "def fetch_word_embeddings(outputs, word_vectors, embed_dim):\n",
    "    outputs_embed = [] \n",
    "    for i, output in enumerate(outputs):\n",
    "        tweet = output['tokens']\n",
    "        embedded_tweet = []\n",
    "\n",
    "        # trim if too large\n",
    "        if len(tweet) >= TWEET_SENTENCE_SIZE:\n",
    "            tweet = tweet[:TWEET_SENTENCE_SIZE]\n",
    "\n",
    "        # convert all into word embeddings\n",
    "        for word in tweet:\n",
    "            embedding = generate_random_embedding(embed_dim) if word not in word_vectors else word_vectors[word]\n",
    "            embedded_tweet.append(embedding)\n",
    "\n",
    "        # pad if too short\n",
    "        if len(tweet) < TWEET_SENTENCE_SIZE:\n",
    "            diff = TWEET_SENTENCE_SIZE - len(tweet)\n",
    "            embedded_tweet += [generate_random_embedding(embed_dim) for _ in range(diff)]\n",
    "\n",
    "        assert len(embedded_tweet) == TWEET_SENTENCE_SIZE\n",
    "        output['word_embeddings'] = embedded_tweet\n",
    "        outputs_embed.append(output)\n",
    "    return outputs_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time 0.7507729848225911 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "embed_dim = 400\n",
    "filename = os.path.join(ROOT_DIR, 'data/word2vec_twitter_model/word2vec_twitter_model.bin')\n",
    "word_vectors = KeyedVectors.load_word2vec_format(filename, binary=True, unicode_errors='ignore')\n",
    "print(\"Total time {} min\".format((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time 0.5721803188323975 min\n",
      "37348 9338 11672\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x_train_embed = fetch_word_embeddings(x_train, word_vectors, embed_dim)\n",
    "x_valid_embed = fetch_word_embeddings(x_valid, word_vectors, embed_dim)\n",
    "x_test_embed = fetch_word_embeddings(x_test, word_vectors, embed_dim)\n",
    "print(\"Total time {} min\".format((time.time() - start) / 60))\n",
    "print(len(x_train_embed), len(x_valid_embed), len(x_test_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label', 'retweet_count', 'retweeted', 'in_reply_to_status_id', 'favorite_count', 'label_string', 'reply_to_tweet_text', 'tokens', 'word_embeddings'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embed[0].keys() # list of dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] #int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'label', 'retweet_count', 'retweeted', 'in_reply_to_status_id', 'favorite_count', 'label_string', 'reply_to_tweet_text', 'tokens', 'word_embeddings'])\n"
     ]
    }
   ],
   "source": [
    "# 17 n-gram \n",
    "# retweet count \n",
    "# in reply to status id \n",
    "# favorite count \n",
    "\n",
    "# 34 n-gram \n",
    "def convert_to_feature_embeddings(x_embed):\n",
    "    return [x['word_embeddings'] for x in x_embed]\n",
    " \n",
    "data = {}\n",
    "print(x_train_embed[0].keys())\n",
    "data['x_train'] = convert_to_feature_embeddings(x_train_embed)\n",
    "data['y_train'] = y_train\n",
    "data['x_valid'] = convert_to_feature_embeddings(x_valid_embed)\n",
    "data['y_valid'] = y_valid\n",
    "data['x_test'] = convert_to_feature_embeddings(x_test_embed)\n",
    "data['y_test'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def wrap_data(batch_size, seed, x_train, y_train, x_valid, y_valid, x_test, y_test):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    transform=None\n",
    "    \n",
    "    train_set = DataProvider(inputs=x_train, targets=y_train, seed=seed, transform=transform)\n",
    "    train_data_local = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   sampler=ImbalancedDatasetSampler(train_set),\n",
    "                                                   )\n",
    "\n",
    "    valid_set = DataProvider(inputs=x_valid, targets=y_valid, seed=seed, transform=transform)\n",
    "    valid_data_local = torch.utils.data.DataLoader(valid_set,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   num_workers=2,\n",
    "                                                   shuffle=False,\n",
    "                                                  )\n",
    "\n",
    "    test_set = DataProvider(inputs=x_test, targets=y_test, seed=seed, transform=transform)\n",
    "    test_data_local = torch.utils.data.DataLoader(test_set,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  num_workers=2,\n",
    "                                                  shuffle=False,\n",
    "                                                 )\n",
    "    return train_data_local, valid_data_local, test_data_local\n",
    "\n",
    "def fetch_model(model, embedding_level, input_shape_local, dropout):\n",
    "    if model == 'MLP':\n",
    "        return multi_layer_perceptron(input_shape_local)\n",
    "    if model == 'CNN':\n",
    "        if embedding_level == 'word':\n",
    "            return word_cnn(input_shape_local, dropout)\n",
    "        elif embedding_level == 'character':\n",
    "            return character_cnn(input_shape_local)\n",
    "    if model == 'DENSENET':\n",
    "        return densenet()\n",
    "    else:\n",
    "        raise ValueError(\"Model key not found {}\".format(embedding_level))\n",
    "\n",
    "\n",
    "def fetch_model_parameters(input_shape_local):\n",
    "    model_local = fetch_model(model='CNN',\n",
    "                            embedding_level='word',\n",
    "                            input_shape_local=input_shape_local,\n",
    "                            dropout=0.5)\n",
    "    criterion_local = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_local = torch.optim.Adam(model_local.parameters(), weight_decay=1e-4)\n",
    "    scheduler_local = optim.lr_scheduler.CosineAnnealingLR(optimizer_local, T_max=100, eta_min=0.0001)\n",
    "    return model_local, criterion_local, optimizer_local, scheduler_local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = wrap_data(2048, 28, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_data:\n",
    "    input_shape = x.shape\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 34, 400)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = tuple(input_shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_iter(model, device, optimizer, criterion, x, y, stats, experiment_key='train'):\n",
    "    \"\"\"\n",
    "    Receives the inputs and targets for the model and runs a training iteration. Returns loss and accuracy metrics.\n",
    "    :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n",
    "    :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n",
    "    :return: the loss and accuracy for this batch\n",
    "    \"\"\"\n",
    "    # sets model to training mode\n",
    "    # (in case batch normalization or other methods have different procedures for training and evaluation)\n",
    "    model.train()\n",
    "    x = x.float()\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    optimizer.zero_grad()  # set all weight grads from previous training iters to 0\n",
    "    out = model.forward(x)  # forward the data in the model\n",
    "    # loss = F.cross_entropy(input=out, target=y)  # compute loss\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()  # backpropagate to compute gradients for current iter loss\n",
    "\n",
    "    optimizer.step()  # update network parameters\n",
    "    _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n",
    "    accuracy = np.mean(list(predicted.eq(y.data).cpu()))  # compute accuracy\n",
    "    stats['{}_acc'.format(experiment_key)].append(accuracy)\n",
    "    stats['{}_loss'.format(experiment_key)].append(loss.data.detach().cpu().numpy())\n",
    "\n",
    "def run_evaluation_iter(model, device, optimizer, criterion, x, y, stats, experiment_key='valid'):\n",
    "    \"\"\"\n",
    "    Receives the inputs and targets for the model and runs an evaluation iterations. Returns loss and accuracy metrics.\n",
    "    :param x: The inputs to the model. A numpy array of shape batch_size, channels, height, width\n",
    "    :param y: The targets for the model. A numpy array of shape batch_size, num_classes\n",
    "    :return: the loss and accuracy for this batch\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # sets the system to validation mode\n",
    "        x = x.float()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model.forward(x)  # forward the data in the model\n",
    "        loss = criterion(out, y)\n",
    "        \n",
    "        # loss = F.cross_entropy(out, y)  # compute loss\n",
    "        _, predicted = torch.max(out.data, 1)  # get argmax of predictions\n",
    "        \n",
    "        accuracy = np.mean(list(predicted.eq(y.data).cpu()))\n",
    "        stats['{}_acc'.format(experiment_key)].append(accuracy)  # compute accuracy\n",
    "        stats['{}_loss'.format(experiment_key)].append(loss.data.detach().cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_save_dir, model_save_name, model_idx):\n",
    "    \"\"\"\n",
    "    Save the network parameter state and current best val epoch idx and best val accuracy.\n",
    "    :param model_save_name: Name to use to save model without the epoch index\n",
    "    :param model_idx: The index to save the model with.\n",
    "    :param best_validation_model_idx: The index of the best validation model to be stored for future use.\n",
    "    :param best_validation_model_acc: The best validation accuracy to be stored for use at test time.\n",
    "    :param model_save_dir: The directory to store the state at.\n",
    "    :param state: The dictionary containing the system state.\n",
    "\n",
    "    \"\"\"\n",
    "    # Save state each epoch\n",
    "    path = os.path.join(model_save_dir, \"{}_{}\".format(model_save_name, str(model_idx)))\n",
    "    torch.save(model.state_dict(), f=path)\n",
    "    \n",
    "\n",
    "def load_model(model, model_save_dir, model_save_name, model_idx):\n",
    "    \"\"\"\n",
    "    Load the network parameter state and the best val model idx and best val acc to be compared with the future val accuracies, in order to choose the best val model\n",
    "    :param model_save_dir: The directory to store the state at.\n",
    "    :param model_save_name: Name to use to save model without the epoch index\n",
    "    :param model_idx: The index to save the model with.\n",
    "    \"\"\"\n",
    "    path = os.path.join(model_save_dir, \"{}_{}\".format(model_save_name, str(model_idx)))\n",
    "    checkpoint = torch.load(f=path)\n",
    "    # freeze parameters\n",
    "    model.load_state_dict(checkpoint)\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building basic block of ConvolutionalNetwork using input shape torch.Size([2048, 400, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block is built, output volume is torch.Size([2048, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.2850, accuracy: 0.4504: 100%|██████████| 19/19 [01:40<00:00,  4.57s/it]\n",
      "loss: 1.3572, accuracy: 0.2574: 100%|██████████| 5/5 [00:14<00:00,  3.13s/it]\n",
      "loss: 1.1754, accuracy: 0.4979: 100%|██████████| 19/19 [01:29<00:00,  2.70s/it]\n",
      "loss: 1.3163, accuracy: 0.2679: 100%|██████████| 5/5 [00:09<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "import tqdm\n",
    "\n",
    "model, criterion, optimizer, _ = fetch_model_parameters(input_shape)\n",
    "device = torch.device('cpu')\n",
    "train_stats = OrderedDict()\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_stats = defaultdict(list)\n",
    "    with tqdm.tqdm(total=len(train_data)) as pbar_train:  # create a progress bar for training\n",
    "        for idx, (x, y) in enumerate(train_data):  # get data batches\n",
    "            run_train_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # take a training iter step\n",
    "            pbar_train.update(1)\n",
    "            pbar_train.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['train_loss'][-1],\n",
    "                                                                               epoch_stats['train_acc'][-1]))\n",
    "\n",
    "    with tqdm.tqdm(total=len(valid_data)) as pbar_val:  # create a progress bar for validation\n",
    "        for x, y in valid_data:  # get data batches\n",
    "            run_evaluation_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats)  # run a validation iter\n",
    "            pbar_val.update(1)  # add 1 step to the progress bar\n",
    "            pbar_val.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['valid_loss'][-1],\n",
    "                                                                             epoch_stats['valid_acc'][-1]))\n",
    "     \n",
    "    \n",
    "    \n",
    "    save_model(model, '', 'testing', epoch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.2806, accuracy: 0.3052: 100%|██████████| 6/6 [00:08<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(model, '', 'testing', 1)\n",
    "\n",
    "#evaluate test here\n",
    "with tqdm.tqdm(total=len(test_data)) as pbar_test:  # create a progress bar for validation\n",
    "    for x, y in test_data:  # get data batches\n",
    "        run_evaluation_iter(model, device, optimizer, criterion, x=x, y=y, stats=epoch_stats, experiment_key=\"test_experiment\")  # run a validation iter\n",
    "        pbar_test.update(1)  # add 1 step to the progress bar\n",
    "        pbar_test.set_description(\"loss: {:.4f}, accuracy: {:.4f}\".format(epoch_stats['test_experiment_loss'][-1],\n",
    "                                                                  epoch_stats['test_experiment_acc'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
